{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Paths:\n",
    "    # Define the absolute base path to your USB\n",
    "    BASE_DIR = \"/media/michael/C60D-9867/COCO\"\n",
    "\n",
    "    # Raw COCO dataset\n",
    "    ANNOTATIONS = f\"{BASE_DIR}/annotations/instances_train2017.json\"\n",
    "    IMAGES_DIR = f\"{BASE_DIR}/train2017/train2017\"\n",
    "\n",
    "    # Processed dataset\n",
    "    PROCESSED_DIR = f\"{BASE_DIR}/processed\"\n",
    "    TRAIN_DIR = f\"{PROCESSED_DIR}/train\"\n",
    "    VAL_DIR = f\"{PROCESSED_DIR}/val\"\n",
    "    RESIZED_DIR = f\"{PROCESSED_DIR}/resized\"\n",
    "\n",
    "    # Test dataset\n",
    "    TEST_DIR = f\"{BASE_DIR}/test\"\n",
    "\n",
    "    # Model directory\n",
    "    MODEL_SAVE_PATH = f\"{BASE_DIR}/models/model.pth\"\n",
    "\n",
    "\n",
    "# Instantiate the global paths object\n",
    "paths = Paths()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing camera test...\n",
      "Loading custom PyTorch model...\n",
      "Model loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40302/2314974686.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(paths.MODEL_SAVE_PATH, map_location=torch.device(\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting live camera testing. Press 'q' to quit.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import os\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.models import ResNet18_Weights\n",
    "\n",
    "\n",
    "# Load the trained PyTorch model\n",
    "def load_model():\n",
    "    print(\"Loading custom PyTorch model...\")\n",
    "    model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "    # Update the last layer to match the number of classes in your training data\n",
    "    model.fc = torch.nn.Linear(model.fc.in_features, len(os.listdir(paths.TRAIN_DIR)))\n",
    "\n",
    "    try:\n",
    "        model.load_state_dict(\n",
    "            torch.load(paths.MODEL_SAVE_PATH, map_location=torch.device(\"cpu\"))\n",
    "        )\n",
    "        print(\"Model loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        exit()\n",
    "\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "# Function to preprocess frames\n",
    "def preprocess_frame(frame):\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "    return transform(frame).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "\n",
    "# Function to perform object detection\n",
    "def detect_objects(frame, model, class_names):\n",
    "    # Preprocess the frame\n",
    "    input_tensor = preprocess_frame(frame)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_tensor)\n",
    "        probabilities = torch.nn.functional.softmax(outputs[0], dim=0)\n",
    "    confidence, predicted_idx = torch.max(probabilities, 0)\n",
    "    predicted_class = class_names[predicted_idx.item()]\n",
    "    return predicted_class, confidence.item()\n",
    "\n",
    "\n",
    "# Draw prediction on the frame\n",
    "def draw_prediction(frame, predicted_class, confidence):\n",
    "    label = f\"{predicted_class} ({confidence:.2f})\"\n",
    "    cv2.putText(\n",
    "        frame,\n",
    "        label,\n",
    "        (10, 30),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        1,\n",
    "        (0, 255, 0),\n",
    "        2,\n",
    "    )\n",
    "    return frame\n",
    "\n",
    "\n",
    "# Main camera testing function\n",
    "def test_camera():\n",
    "    print(\"Initializing camera test...\")\n",
    "\n",
    "    # Load the trained model\n",
    "    model = load_model()\n",
    "\n",
    "    # Load class names from training directory\n",
    "    class_names = os.listdir(paths.TRAIN_DIR)\n",
    "\n",
    "    # Open the webcam\n",
    "    cap = cv2.VideoCapture(9)  # Replace with the correct camera index\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open the camera.\")\n",
    "        return\n",
    "\n",
    "    print(\"Starting live camera testing. Press 'q' to quit.\")\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Could not read frame from camera.\")\n",
    "            break\n",
    "\n",
    "        # Convert BGR frame to RGB for PyTorch\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Detect objects in the frame\n",
    "        predicted_class, confidence = detect_objects(rgb_frame, model, class_names)\n",
    "\n",
    "        # Draw the prediction on the frame\n",
    "        frame = draw_prediction(frame, predicted_class, confidence)\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow(\"Live Object Detection\", frame)\n",
    "\n",
    "        # Quit on pressing 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Camera test ended.\")\n",
    "\n",
    "test_camera()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tfod)",
   "language": "python",
   "name": "tfod"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
